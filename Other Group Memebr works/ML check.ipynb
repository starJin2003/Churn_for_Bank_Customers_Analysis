{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947f3056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (0.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/srihithduggi/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7f95f",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e865d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1533   74]\n",
      " [ 197  196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1607\n",
      "           1       0.73      0.50      0.59       393\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.73      0.76      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "Accuracy:  0.8645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"churn.csv\")\n",
    "\n",
    "# Preprocess the data (One-hot encode categorical variables, remove unnecessary columns, etc.)\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)  # Drop unnecessary columns\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = [\"Geography\", \"Gender\"]\n",
    "one_hot_encoder = OneHotEncoder(drop=\"first\")  # Use 'drop=\"first\"' to avoid the dummy variable trap\n",
    "column_transformer = ColumnTransformer(transformers=[(\"encoder\", one_hot_encoder, categorical_features)], remainder=\"passthrough\")\n",
    "X = column_transformer.fit_transform(data.drop(\"Exited\", axis=1))\n",
    "y = data[\"Exited\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf7f06",
   "metadata": {},
   "source": [
    "#### The confusion matrix is a table that describes the performance of a classification model. It compares the predicted labels with the true labels. In this case:\n",
    "\n",
    "1526 true negatives (TN): customers correctly predicted as not churning\n",
    "\n",
    "81 false positives (FP): customers incorrectly predicted as churning\n",
    "\n",
    "212 false negatives (FN): customers incorrectly predicted as not churning\n",
    "\n",
    "181 true positives (TP): customers correctly predicted as churning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a8ee8",
   "metadata": {},
   "source": [
    "#### Accuracy Score\n",
    "The accuracy score is 0.8535, which means the classifier correctly predicted the class for 85.35% of the test instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324c36b",
   "metadata": {},
   "source": [
    "### RandomForrestClassifier_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983e585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1552   55]\n",
      " [ 204  189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1607\n",
      "           1       0.77      0.48      0.59       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "Accuracy:  0.8705\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"churn.csv\")\n",
    "\n",
    "# Preprocess the data (One-hot encode categorical variables, remove unnecessary columns, etc.)\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)  # Drop unnecessary columns\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = [\"Geography\", \"Gender\"]\n",
    "one_hot_encoder = OneHotEncoder(drop=\"first\")  # Use 'drop=\"first\"' to avoid the dummy variable trap\n",
    "column_transformer = ColumnTransformer(transformers=[(\"encoder\", one_hot_encoder, categorical_features)], remainder=\"passthrough\")\n",
    "X = column_transformer.fit_transform(data.drop(\"Exited\", axis=1))\n",
    "y = data[\"Exited\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predictions = rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0b068",
   "metadata": {},
   "source": [
    "#### The confusion matrix compares the predicted labels with the true labels. In this case:\n",
    "\n",
    "1552 true negatives (TN): customers correctly predicted as not churning\n",
    "\n",
    "55 false positives (FP): customers incorrectly predicted as churning\n",
    "\n",
    "204 false negatives (FN): customers incorrectly predicted as not churning\n",
    "\n",
    "189 true positives (TP): customers correctly predicted as churning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73249f48",
   "metadata": {},
   "source": [
    "#### Accuracy: \n",
    "The proportion of correct predictions over the total number of predictions. In this case, the accuracy is 0.8705, meaning the classifier made correct predictions for 87.05% of the test instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c932596",
   "metadata": {},
   "source": [
    "### RandomForestClassifier_2 with hyperparameter tuning and SMOTE for handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e628d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1532   75]\n",
      " [ 198  195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1607\n",
      "           1       0.72      0.50      0.59       393\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.72      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "Accuracy:  0.8635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"churn.csv\")\n",
    "\n",
    "# Preprocess the data (One-hot encode categorical variables, remove unnecessary columns, etc.)\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)  # Drop unnecessary columns\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = [\"Geography\", \"Gender\"]\n",
    "one_hot_encoder = OneHotEncoder(drop=\"first\")  # Use 'drop=\"first\"' to avoid the dummy variable trap\n",
    "column_transformer = ColumnTransformer(transformers=[(\"encoder\", one_hot_encoder, categorical_features)], remainder=\"passthrough\")\n",
    "X = column_transformer.fit_transform(data.drop(\"Exited\", axis=1))\n",
    "y = data[\"Exited\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Perform hyperparameter tuning using grid search\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predictions = best_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd84fa9",
   "metadata": {},
   "source": [
    "#### The confusion matrix compares the predicted labels with the true labels. In this case:\n",
    "\n",
    "1532 true negatives (TN): customers correctly predicted as not churning\n",
    "\n",
    "75 false positives (FP): customers incorrectly predicted as churning\n",
    "\n",
    "198 false negatives (FN): customers incorrectly predicted as not churning\n",
    "\n",
    "195 true positives (TP): customers correctly predicted as churning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba72a5f",
   "metadata": {},
   "source": [
    "#### Accuracy:\n",
    "The accuracy score is 0.8635, which means the classifier correctly predicted the class for 86.35% of the test instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a8789",
   "metadata": {},
   "source": [
    "##### MLPClassifier:\n",
    "\n",
    "Accuracy: 0.853\n",
    "\n",
    "True positives: 186\n",
    "\n",
    "True negatives: 1520\n",
    "\n",
    "False positives: 87\n",
    "\n",
    "False negatives: 207\n",
    "\n",
    "##### RandomForrestClassifier_1:\n",
    "\n",
    "Accuracy: 0.8705\n",
    "\n",
    "True positives: 189\n",
    "\n",
    "True negatives: 1552\n",
    "\n",
    "False positives: 55\n",
    "\n",
    "False negatives: 204"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9250ac5",
   "metadata": {},
   "source": [
    "While the RandomForestClassifier_2 has a slightly lower accuracy (0.8635) compared to the RandomForestClassifier_1 (0.8705), it has a better balance between precision and recall for the positive class (churners). The RandomForestClassifier_2 has a precision of 0.72 and recall of 0.50 for the positive class, while the RandomForestClassifier_1 has a precision of 0.77 and recall of 0.48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3c034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
